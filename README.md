Data Collection:
----------------
Dataset: LinkedIn job postings from 2024 with over 1.3 million records.
Source: [Kaggle Dataset](https://www.kaggle.com/datasets/asaniczka/1-3m-linkedin-jobs-and-skills-2024)

Data Preparation:
----------------
Data cleaning, selection, and construction processes were applied to improve data quality.
Feature engineering was conducted, focusing on job frequency analysis.

Data Mining Methods:
-------------------
Clustering (KMeans) and classification (Random Forest) algorithms were used for identifying job demand trends.
Evaluation metrics include accuracy, ROC curves, and feature importance analysis.
Files
assignment4 folder contains all project code and the dataset.
Final results include the clustered and classified job data with visualization outputs.

How to Run
-------------------
Set up a Python environment with the required libraries: Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, and PySpark.
Clone the repository: https://github.com/Hahamob/aws-instance
Execute the Jupyter notebooks to see data analysis and visualizations.

Results
---------------------
Insights into the demand for various job titles.
Visualizations for job types, companies by postings, and job levels.
